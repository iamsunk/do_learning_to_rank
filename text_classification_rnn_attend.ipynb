{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문장 분류시에 rnn,rcnn + attention 메커니즘에 대해 실험해본다.\n",
    "## 임베딩시에 fast-text & 아래 논문의 내용을 참고하여 비슷하게 해본다\n",
    "http://aclweb.org/anthology/P18-1226 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy\n",
    "sentence = u'만 6세 이하의 초등학교 취학 전 자녀를 양육하기 위해서는'\n",
    "words = konlpy.tag.Twitter().morphs(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.utils import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()\n",
    "    keys_list = [keys for keys in flags_dict]\n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "        \n",
    "del_all_flags(tf.flags.FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(inputs, attention_size):\n",
    "    if isinstance(inputs, tuple):\n",
    "        inputs = tf.concat(2, inputs)\n",
    "\n",
    "    sequence_length = inputs.get_shape()[1].value\n",
    "    hidden_size = inputs.get_shape()[2].value  \n",
    "\n",
    "    # Attention mechanism\n",
    "    W_omega = tf.Variable(tf.random_normal([hidden_size, attention_size], stddev=0.1))\n",
    "    b_omega = tf.Variable(tf.random_normal([attention_size], stddev=0.1))\n",
    "    u_omega = tf.Variable(tf.random_normal([attention_size], stddev=0.1))\n",
    "\n",
    "    v = tf.tanh(tf.matmul(tf.reshape(inputs, [-1, hidden_size]), W_omega) + tf.reshape(b_omega, [1, -1]))\n",
    "    vu = tf.matmul(v, tf.reshape(u_omega, [-1, 1]))\n",
    "    exps = tf.reshape(tf.exp(vu), [-1, sequence_length])\n",
    "    alphas = exps / tf.reshape(tf.reduce_sum(exps, 1), [-1, 1])\n",
    "\n",
    "    # Output of Bi-RNN is reduced with attention vector\n",
    "    output = tf.reduce_sum(inputs * tf.reshape(alphas, [-1, sequence_length, 1]), 1)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.app.flags.DEFINE_string('VOCAB_DIR', './data/vocab/vocab.txt', 'VocabularyProcessor object file path')\n",
    "tf.app.flags.DEFINE_integer('EMBEDDING_SIZE', 300, 'Dimension of embedded terms')\n",
    "# Class\n",
    "tf.app.flags.DEFINE_integer('NUM_OF_CLASS', 2, 'positive, negative')\n",
    "\n",
    "# Parameter\n",
    "tf.app.flags.DEFINE_integer('ATTENTION_SIZE', 100, 'attention dimension')\n",
    "tf.app.flags.DEFINE_integer('FC_HIDDEN_DIMENSION', 10, 'FC hidden dimension')\n",
    "tf.app.flags.DEFINE_float('Dropout_Rate', 0.8, 'Dropout_Rate1')\n",
    "tf.app.flags.DEFINE_integer('NUM_LAYERS', 3, 'The number of layers')\n",
    "\n",
    "# Train\n",
    "tf.app.flags.DEFINE_integer('BATCH_SIZE', 128, 'batch size')\n",
    "tf.app.flags.DEFINE_integer('TEST_BATCH', 128, 'test batch size')\n",
    "tf.app.flags.DEFINE_integer('NUM_OF_EPOCH', 3, 'number of epoch')\n",
    "tf.app.flags.DEFINE_float('lr_value', 0.001, 'initial learning rate')\n",
    "tf.app.flags.DEFINE_float('lr_decay', 0.7, 'learning rate decay')\n",
    "\n",
    "# FLAGS\n",
    "FLAGS = tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ATTENTION_SIZE': 100,\n",
       " 'BATCH_SIZE': 128,\n",
       " 'Dropout_Rate': 0.8,\n",
       " 'EMBEDDING_SIZE': 300,\n",
       " 'FC_HIDDEN_DIMENSION': 10,\n",
       " 'NUM_LAYERS': 3,\n",
       " 'NUM_OF_CLASS': 2,\n",
       " 'NUM_OF_EPOCH': 3,\n",
       " 'TEST_BATCH': 128,\n",
       " 'VOCAB_DIR': './data/vocab/vocab.txt',\n",
       " 'lr_decay': 0.7,\n",
       " 'lr_value': 0.001}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.app.flags.FLAGS.flag_values_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow' from '/home1/irteam/anaconda2/lib/python2.7/site-packages/tensorflow/__init__.pyc'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnrecognizedFlagError",
     "evalue": "Unknown command line flag 'f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mUnrecognizedFlagError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-933cb1cc1d1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home1/irteam/anaconda2/lib/python2.7/site-packages/tensorflow/python/platform/flags.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# a flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m       \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/irteam/anaconda2/lib/python2.7/site-packages/absl/flags/_flagvalues.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, argv, known_only)\u001b[0m\n\u001b[1;32m    628\u001b[0m       \u001b[0msuggestions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_flag_suggestions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       raise _exceptions.UnrecognizedFlagError(\n\u001b[0;32m--> 630\u001b[0;31m           name, value, suggestions=suggestions)\n\u001b[0m\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnrecognizedFlagError\u001b[0m: Unknown command line flag 'f'"
     ]
    }
   ],
   "source": [
    "print(FLAGS.lr_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-53-b51740622201>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-53-b51740622201>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    shape=[FLAGS.VOCAB_S])\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    def __init__(self,args):\n",
    "        self.learning_rate = args.learning_rate #1.0\n",
    "        self.num_layers = args.num_layers #1\n",
    "        self.hidden_size = args.hidden_size #128\n",
    "        self.maxSeqLength = 0\n",
    "        self.batch_size = args.batch_size #32\n",
    "    #    vocab_size = 20000\n",
    "        self.max_max_epoch = args.max_max_epoch #10\n",
    "        self.n_classes = args.n_classes\n",
    "        self.init_scale = 0.1\n",
    "        self.max_grad_norm = 5\n",
    "        self.max_epoch = 5      #keep learning rate at initial value for max_epoch iterations\n",
    "        self.keep_prob = 0.5\n",
    "        self.lr = 0.001\n",
    "        self.summary = 0.001\n",
    "        self.checkpoint_num = 500\n",
    "        \n",
    "class Model():\n",
    "    def __init__(self, sess, modelConf):\n",
    "        self.inputX = tf.placeholder(shape=[None,modelConf.maxLength])\n",
    "        self.inputY = tf.placeholder(shape=[None,modelConf.NUM_CLASS])\n",
    "        self.lr = modelConf.learnignRate        \n",
    "        self.numEpoch = modelConf.epoch\n",
    "        \n",
    "    def modelStructure(self):\n",
    "        with tf.variable_scope('embedding'):\n",
    "            self.W = tf.get_variable(name=\"embedding_w\"\n",
    "                                    shape=[NONE,FLAGS.EMBEDDING_SIZE],\n",
    "                                    initializer = tf.random_normal_initializer(stddev=0.1))\n",
    "            self.X = tf.nn.embedding_lookup(self.W,self.inputX)\n",
    "            \n",
    "            with tf.variable_scope(\"rnn_cell\"):\n",
    "                \n",
    "                \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
